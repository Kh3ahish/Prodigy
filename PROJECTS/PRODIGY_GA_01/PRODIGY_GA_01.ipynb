{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e86bcd",
   "metadata": {},
   "source": [
    "# Function to Update and Use Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78629318",
   "metadata": {},
   "source": [
    "# Integrated with Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736ab243",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gradio\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git\n",
    "\n",
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "!pip install --upgrade gradio\n",
    "\n",
    "\n",
    "def update_memory(key, value):\n",
    "    memory[key] = value\n",
    "    return f\"Momory updated: {key} is now {value}\"\n",
    "\n",
    "def generate_text(inp):\n",
    "    input_ids = tokenizer.encode(inp, return_tensors='tf')\n",
    "    beam_output = model.generate (input_ids, max_length=100, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "    Output = tokenizer.decode(beam_output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return \".\".join(Output.split(\".\")[:-1]) + \".\"\n",
    "\n",
    "\n",
    "from transformers import GPT2Tokenizer,TFGPT2LMHeadModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f8613",
   "metadata": {},
   "source": [
    "Load tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065cd24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model=TFGPT2LMHeadModel.from_pretrained(\"gpt2\",pad_token_id=tokenizer.eos_token_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f02cb",
   "metadata": {},
   "source": [
    "Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f72a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_memory(key,value):\n",
    "  memory[key]=value\n",
    "  return f\"Memory updated: {key} is now {value}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd47f1",
   "metadata": {},
   "source": [
    "Create gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_textbox = gr.Textbox(lines=2,placeholder=\"Enter a sentence...\")\n",
    "memory_key_textbox= gr.Textbox(lines=1,placeholder=\"Memory key...\")\n",
    "memory_value_textbox=gr.Textbox(lines=1,placeholder=\"Memory value...\")\n",
    "\n",
    "generate_btn=gr.Button(\"Generate Text\")\n",
    "update_memory_btn=gr.Button(\"Update Memory\")\n",
    "\n",
    "generate_text_interface=gr.Interface(fn=generate_text,inputs=input_textbox,outputs=\"text\",title=\"GPT-2 Text Generation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8a84b3",
   "metadata": {},
   "source": [
    "Launch the interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21be6a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.TabbedInterface([generate_text_interface], tab_names = [\"Generate Text\"]).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a277a55",
   "metadata": {},
   "source": [
    "Created with ❤️ by Khwahish Kushwah"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
